{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a619e99-e411-420a-9750-805c8ca2ffe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/pc_win_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eda95659-c1f8-4b3f-9a47-981cd897297b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoost, CatBoostClassifier, Pool\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from functions.visualizer import *\n",
    "from src.config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b646bc-ede6-4094-83e4-05269cf8a03e",
   "metadata": {},
   "source": [
    "# データ取り込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18b06f1e-862e-47cb-aec5-b810ec7faff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blueFirstBlood</th>\n",
       "      <th>blueKills</th>\n",
       "      <th>blueDeaths</th>\n",
       "      <th>blueAssists</th>\n",
       "      <th>blueEliteMonsters</th>\n",
       "      <th>blueDragons</th>\n",
       "      <th>blueTotalGold</th>\n",
       "      <th>blueTotalExperience</th>\n",
       "      <th>blueWins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14536</td>\n",
       "      <td>17256</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14536</td>\n",
       "      <td>17863</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17409</td>\n",
       "      <td>17256</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19558</td>\n",
       "      <td>18201</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17409</td>\n",
       "      <td>17256</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   blueFirstBlood  blueKills  blueDeaths  blueAssists  blueEliteMonsters  \\\n",
       "0               0          5           8            6                  0   \n",
       "1               1         10           1            5                  0   \n",
       "2               0          3          10            2                  0   \n",
       "3               1          7          10            8                  0   \n",
       "4               0          4           9            4                  0   \n",
       "\n",
       "   blueDragons  blueTotalGold  blueTotalExperience  blueWins  \n",
       "0            0          14536                17256         0  \n",
       "1            0          14536                17863         0  \n",
       "2            0          17409                17256         0  \n",
       "3            0          19558                18201         0  \n",
       "4            0          17409                17256         0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prep = pd.read_pickle('output/df_prep.pkl')\n",
    "df_prep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "626594b8-03eb-4521-89c4-2bf3da2e35b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df_prep.drop(COL_BLUEWINS, axis=1)\n",
    "y = df_prep[COL_BLUEWINS]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66a938d-16a0-4450-bc32-1b9f28870921",
   "metadata": {},
   "source": [
    "# モデル構築"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d9f2c6-db72-4376-b2a3-da4aa3d923dc",
   "metadata": {},
   "source": [
    "## 関数定義"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1929f7b-7187-48ce-8437-9799e20d196a",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d593ac6-0b62-4f3e-8f1b-d504fb9ac3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def lgbm_train_cv(X_train_cv, y_train_cv, X_eval_cv, y_eval_cv):\\n    # データを格納する\\n    # 学習用\\n    lgb_train = lgb.Dataset(X_train_cv, y_train_cv,\\n                            free_raw_data=False)\\n    # 検証用\\n    lgb_eval = lgb.Dataset(X_eval_cv, y_eval_cv, reference=lgb_train,\\n                           free_raw_data=False)\\n\\n    # 学習\\n    evaluation_results = {}\\n    model = lgb.LGBMClassifier()\\n    model.fit(X_train_cv, y_train_cv)\\n    \\n    # 検証用データで予測\\n    y_pred = model.predict(X_eval_cv)\\n    # y_pred_max = np.argmax(y_pred, axis=1)\\n\\n    # Accuracy の計算\\n    # accuracy = accuracy_score(y_eval_cv, y_pred_max)\\n    accuracy = accuracy_score(y_eval_cv, y_pred)\\n    print('LightGBM Accuracy:', accuracy)\\n    \\n    return(model, accuracy, y_pred)\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def lgbm_train_cv(X_train_cv, y_train_cv, X_eval_cv, y_eval_cv):\n",
    "    # データを格納する\n",
    "    # 学習用\n",
    "    lgb_train = lgb.Dataset(X_train_cv, y_train_cv,\n",
    "                            free_raw_data=False)\n",
    "    # 検証用\n",
    "    lgb_eval = lgb.Dataset(X_eval_cv, y_eval_cv, reference=lgb_train,\n",
    "                           free_raw_data=False)\n",
    "\n",
    "    # 学習\n",
    "    evaluation_results = {}\n",
    "    model = lgb.LGBMClassifier()\n",
    "    model.fit(X_train_cv, y_train_cv)\n",
    "    \n",
    "    # 検証用データで予測\n",
    "    y_pred = model.predict(X_eval_cv)\n",
    "    # y_pred_max = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    # Accuracy の計算\n",
    "    # accuracy = accuracy_score(y_eval_cv, y_pred_max)\n",
    "    accuracy = accuracy_score(y_eval_cv, y_pred)\n",
    "    print('LightGBM Accuracy:', accuracy)\n",
    "    \n",
    "    return(model, accuracy, y_pred)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a55abb9-d6f4-4c5e-8369-7a18c302bb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_train_cv(X_train_cv, y_train_cv, X_eval_cv, y_eval_cv):\n",
    "    # データを格納する\n",
    "    # 学習用\n",
    "    lgb_train = lgb.Dataset(X_train_cv, y_train_cv,\n",
    "                            free_raw_data=False)\n",
    "    # 検証用\n",
    "    lgb_eval = lgb.Dataset(X_eval_cv, y_eval_cv, reference=lgb_train,\n",
    "                           free_raw_data=False)\n",
    "    \n",
    "    # パラメータを設定\n",
    "    params = {'task': 'train',                # レーニング ⇔　予測predict\n",
    "              'boosting_type': 'gbdt',        # 勾配ブースティング\n",
    "              'objective': 'multiclass',      # 目的関数：多値分類、マルチクラス分類\n",
    "              'metric': 'multi_logloss',      # 検証用データセットで、分類モデルの性能を測る指標\n",
    "              'num_class': 2,                 # 目的変数のクラス数\n",
    "              'learning_rate': 0.1,           # 学習率（初期値0.1）\n",
    "              'num_leaves': 23,               # 決定木の複雑度を調整（初期値31）\n",
    "              'min_data_in_leaf': 1,          # データの最小数（初期値20）\n",
    "             }\n",
    "\n",
    "    # 学習\n",
    "    evaluation_results = {}                                # 学習の経過を保存する箱\n",
    "    model = lgb.train(params,                              # 上記で設定したパラメータ\n",
    "                      lgb_train,                           # 使用するデータセット\n",
    "                      num_boost_round=200,                 # 学習の回数\n",
    "                      valid_names=['train', 'valid'],      # 学習経過で表示する名称\n",
    "                      valid_sets=[lgb_train, lgb_eval],    # モデルの検証に使用するデータセット\n",
    "                      evals_result=evaluation_results,     # 学習の経過を保存\n",
    "                      early_stopping_rounds=10,            # アーリーストッピングの回数\n",
    "                      verbose_eval=0)                      # 学習の経過を表示する刻み（非表示）\n",
    "\n",
    "    # 検証用データで予測\n",
    "    y_pred = model.predict(X_eval_cv, num_iteration=model.best_iteration)\n",
    "    y_pred_max = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    # Accuracy の計算\n",
    "    accuracy = accuracy_score(y_eval_cv, y_pred_max)\n",
    "    print('LightGBM Accuracy:', accuracy)\n",
    "    \n",
    "    return(model, accuracy, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafe98a2-167f-4760-8904-a2bf54dbf04f",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b249943-6426-4474-b836-79d248500412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def xgb_train_cv(X_train_cv, y_train_cv, X_eval_cv, y_eval_cv, loop_counts):\\n    # データを格納する\\n    # 学習用\\n    xgb_train = xgb.DMatrix(X_train_cv, label=y_train_cv)\\n    # 検証用\\n    xgb_eval = xgb.DMatrix(X_eval_cv, label=y_eval_cv)\\n    # テスト用\\n    #xgb_test = xgb.DMatrix(X_test, label=y_test)\\n\\n    xgb_params = {\\n        'learning_rate': 0.05,           # 学習率\\n        'max_depth': 6, \\n        'min_child_weight': 9, \\n        'n_estimators': 200\\n    }\\n\\n    # 学習\\n    evals = [(xgb_train, 'train'), (xgb_eval, 'eval')] # 学習に用いる検証用データ\\n    evaluation_results = {}                            # 学習の経過を保存する箱\\n    bst = xgb.XGBClassifier(\\n                        learning_rate=0.05, \\n                        max_depth=6, \\n                        min_child_weight=9, \\n                        n_estimators=200\\n                         )\\n    bst.fit(X_train_cv, y_train_cv)\\n    \\n    # 検証用データで予測\\n    y_pred = bst.predict(X_eval_cv)\\n\\n    print('Trial: ' + str(loop_counts))\\n    \\n    # Accuracy の計算\\n    accuracy = accuracy_score(y_eval_cv, y_pred)\\n    print('XGBoost Accuracy:', accuracy)\\n    \\n    return(bst, accuracy, y_pred)\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def xgb_train_cv(X_train_cv, y_train_cv, X_eval_cv, y_eval_cv, loop_counts):\n",
    "    # データを格納する\n",
    "    # 学習用\n",
    "    xgb_train = xgb.DMatrix(X_train_cv, label=y_train_cv)\n",
    "    # 検証用\n",
    "    xgb_eval = xgb.DMatrix(X_eval_cv, label=y_eval_cv)\n",
    "    # テスト用\n",
    "    #xgb_test = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "    xgb_params = {\n",
    "        'learning_rate': 0.05,           # 学習率\n",
    "        'max_depth': 6, \n",
    "        'min_child_weight': 9, \n",
    "        'n_estimators': 200\n",
    "    }\n",
    "\n",
    "    # 学習\n",
    "    evals = [(xgb_train, 'train'), (xgb_eval, 'eval')] # 学習に用いる検証用データ\n",
    "    evaluation_results = {}                            # 学習の経過を保存する箱\n",
    "    bst = xgb.XGBClassifier(\n",
    "                        learning_rate=0.05, \n",
    "                        max_depth=6, \n",
    "                        min_child_weight=9, \n",
    "                        n_estimators=200\n",
    "                         )\n",
    "    bst.fit(X_train_cv, y_train_cv)\n",
    "    \n",
    "    # 検証用データで予測\n",
    "    y_pred = bst.predict(X_eval_cv)\n",
    "\n",
    "    print('Trial: ' + str(loop_counts))\n",
    "    \n",
    "    # Accuracy の計算\n",
    "    accuracy = accuracy_score(y_eval_cv, y_pred)\n",
    "    print('XGBoost Accuracy:', accuracy)\n",
    "    \n",
    "    return(bst, accuracy, y_pred)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc47d45e-7bee-4306-bd1b-f26ba7e051f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_train_cv(X_train_cv, y_train_cv, X_eval_cv, y_eval_cv, loop_counts):\n",
    "    # データを格納する\n",
    "    # 学習用\n",
    "    xgb_train = xgb.DMatrix(X_train_cv, label=y_train_cv)\n",
    "    # 検証用\n",
    "    xgb_eval = xgb.DMatrix(X_eval_cv, label=y_eval_cv)\n",
    "    # テスト用\n",
    "    #xgb_test = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "    xgb_params = {\n",
    "        'objective': 'multi:softprob',  # 多値分類問題\n",
    "        'num_class': 2,                 # 目的変数のクラス数\n",
    "        'learning_rate': 0.1,           # 学習率\n",
    "        'eval_metric': 'mlogloss'       # 学習用の指標 (Multiclass logloss)\n",
    "    }\n",
    "\n",
    "    # 学習\n",
    "    evals = [(xgb_train, 'train'), (xgb_eval, 'eval')] # 学習に用いる検証用データ\n",
    "    evaluation_results = {}                            # 学習の経過を保存する箱\n",
    "    bst = xgb.train(xgb_params,                        # 上記で設定したパラメータ\n",
    "                    xgb_train,                         # 使用するデータセット\n",
    "                    num_boost_round=200,               # 学習の回数\n",
    "                    early_stopping_rounds=10,          # アーリーストッピング\n",
    "                    evals=evals,                       # 学習経過で表示する名称\n",
    "                    evals_result=evaluation_results,   # 上記で設定した検証用データ\n",
    "                    verbose_eval=0                     # 学習の経過の表示(非表示)\n",
    "                    )\n",
    "    \n",
    "    # 検証用データで予測\n",
    "    y_pred = bst.predict(xgb_eval, ntree_limit=bst.best_ntree_limit)\n",
    "    y_pred_max = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    print('Trial: ' + str(loop_counts))\n",
    "    \n",
    "    # Accuracy の計算\n",
    "    accuracy = accuracy_score(y_eval_cv, y_pred_max)\n",
    "    print('XGBoost Accuracy:', accuracy)\n",
    "    \n",
    "    return(bst, accuracy, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c74ead8-0b4b-4ee6-abf1-d478788b7e39",
   "metadata": {},
   "source": [
    "### CαtBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97d5592c-3643-4195-902b-b4e38ec4e3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def catboost_train_cv(X_train_cv, y_train_cv, X_eval_cv, y_eval_cv):\\n    # データを格納する\\n    # 学習用\\n    CatBoost_train = Pool(X_train_cv, label=y_train_cv)\\n    # 検証用\\n    CatBoost_eval = Pool(X_eval_cv, label=y_eval_cv)\\n\\n    # 学習\\n    catb = CatBoostClassifier(custom_loss=['Accuracy'])\\n    catb.fit(X_train_cv, y_train_cv, verbose=False)\\n\\n    # 検証用データで予測\\n    y_pred = catb.predict(X_eval_cv)\\n    # y_pred_max = np.argmax(y_pred, axis=1)\\n\\n    # Accuracy の計算\\n    # accuracy = sum(y_eval_cv == y_pred_max) / len(y_eval_cv)\\n    accuracy = accuracy_score(y_eval_cv, y_pred)\\n    print('CatBoost Accuracy:', accuracy)\\n    \\n    return(catb, accuracy, y_pred)\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def catboost_train_cv(X_train_cv, y_train_cv, X_eval_cv, y_eval_cv):\n",
    "    # データを格納する\n",
    "    # 学習用\n",
    "    CatBoost_train = Pool(X_train_cv, label=y_train_cv)\n",
    "    # 検証用\n",
    "    CatBoost_eval = Pool(X_eval_cv, label=y_eval_cv)\n",
    "\n",
    "    # 学習\n",
    "    catb = CatBoostClassifier(custom_loss=['Accuracy'])\n",
    "    catb.fit(X_train_cv, y_train_cv, verbose=False)\n",
    "\n",
    "    # 検証用データで予測\n",
    "    y_pred = catb.predict(X_eval_cv)\n",
    "    # y_pred_max = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    # Accuracy の計算\n",
    "    # accuracy = sum(y_eval_cv == y_pred_max) / len(y_eval_cv)\n",
    "    accuracy = accuracy_score(y_eval_cv, y_pred)\n",
    "    print('CatBoost Accuracy:', accuracy)\n",
    "    \n",
    "    return(catb, accuracy, y_pred)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73b1759a-6bdc-4932-a70a-6d9aada2682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def catboost_train_cv(X_train_cv, y_train_cv, X_eval_cv, y_eval_cv):\n",
    "    # データを格納する\n",
    "    # 学習用\n",
    "    CatBoost_train = Pool(X_train_cv, label=y_train_cv)\n",
    "    # 検証用\n",
    "    CatBoost_eval = Pool(X_eval_cv, label=y_eval_cv)\n",
    "\n",
    "    # パラメータを設定\n",
    "    params = {        \n",
    "        'loss_function': 'MultiClass',    # 多値分類問題\n",
    "        'num_boost_round': 1000,          # 学習の回数\n",
    "        'early_stopping_rounds': 10       # アーリーストッピングの回数\n",
    "    }\n",
    "\n",
    "    # 学習\n",
    "    catb = CatBoost(params)\n",
    "    catb.fit(CatBoost_train, eval_set=[CatBoost_eval], verbose=False)\n",
    "\n",
    "    # 検証用データで予測\n",
    "    y_pred = catb.predict(X_eval_cv, prediction_type='Probability')\n",
    "    y_pred_max = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    # Accuracy の計算\n",
    "    accuracy = sum(y_eval_cv == y_pred_max) / len(y_eval_cv)\n",
    "    print('CatBoost Accuracy:', accuracy)\n",
    "    \n",
    "    return(catb, accuracy, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed14f10-8b25-46c4-a4cf-8825282b19ea",
   "metadata": {},
   "source": [
    "## アンサンブル学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2137c3b-351b-4b93-96ff-4f39c2f99577",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 1\n",
      "XGBoost Accuracy: 0.77875\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000844 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 99\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -0.677028\n",
      "[LightGBM] [Info] Start training from score -0.709531\n",
      "LightGBM Accuracy: 0.78\n",
      "CatBoost Accuracy: 0.780625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 2\n",
      "XGBoost Accuracy: 0.798125\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000824 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 98\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -0.676720\n",
      "[LightGBM] [Info] Start training from score -0.709848\n",
      "LightGBM Accuracy: 0.80625\n",
      "CatBoost Accuracy: 0.80375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 3\n",
      "XGBoost Accuracy: 0.778125\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002082 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 99\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -0.676720\n",
      "[LightGBM] [Info] Start training from score -0.709848\n",
      "LightGBM Accuracy: 0.7775\n",
      "CatBoost Accuracy: 0.775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 4\n",
      "XGBoost Accuracy: 0.791875\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002032 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 98\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -0.676720\n",
      "[LightGBM] [Info] Start training from score -0.709848\n",
      "LightGBM Accuracy: 0.783125\n",
      "CatBoost Accuracy: 0.789375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 5\n",
      "XGBoost Accuracy: 0.778125\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000823 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 98\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -0.676720\n",
      "[LightGBM] [Info] Start training from score -0.709848\n",
      "LightGBM Accuracy: 0.78125\n",
      "CatBoost Accuracy: 0.7775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 6\n",
      "XGBoost Accuracy: 0.77875\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004546 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 99\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -0.677028\n",
      "[LightGBM] [Info] Start training from score -0.709531\n",
      "LightGBM Accuracy: 0.78\n",
      "CatBoost Accuracy: 0.780625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 7\n",
      "XGBoost Accuracy: 0.798125\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001333 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 98\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -0.676720\n",
      "[LightGBM] [Info] Start training from score -0.709848\n",
      "LightGBM Accuracy: 0.80625\n",
      "CatBoost Accuracy: 0.80375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 8\n",
      "XGBoost Accuracy: 0.778125\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000914 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 99\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -0.676720\n",
      "[LightGBM] [Info] Start training from score -0.709848\n",
      "LightGBM Accuracy: 0.7775\n",
      "CatBoost Accuracy: 0.775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 9\n",
      "XGBoost Accuracy: 0.791875\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005060 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 98\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -0.676720\n",
      "[LightGBM] [Info] Start training from score -0.709848\n",
      "LightGBM Accuracy: 0.783125\n",
      "CatBoost Accuracy: 0.789375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 10\n",
      "XGBoost Accuracy: 0.778125\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 98\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -0.676720\n",
      "[LightGBM] [Info] Start training from score -0.709848\n",
      "LightGBM Accuracy: 0.78125\n",
      "CatBoost Accuracy: 0.7775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 11\n",
      "XGBoost Accuracy: 0.77875\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001969 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 99\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -0.677028\n",
      "[LightGBM] [Info] Start training from score -0.709531\n",
      "LightGBM Accuracy: 0.78\n",
      "CatBoost Accuracy: 0.780625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 12\n",
      "XGBoost Accuracy: 0.798125\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000957 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 98\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -0.676720\n",
      "[LightGBM] [Info] Start training from score -0.709848\n",
      "LightGBM Accuracy: 0.80625\n",
      "CatBoost Accuracy: 0.80375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 13\n",
      "XGBoost Accuracy: 0.778125\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001083 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 99\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -0.676720\n",
      "[LightGBM] [Info] Start training from score -0.709848\n",
      "LightGBM Accuracy: 0.7775\n",
      "CatBoost Accuracy: 0.775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 14\n",
      "XGBoost Accuracy: 0.791875\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001780 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 98\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -0.676720\n",
      "[LightGBM] [Info] Start training from score -0.709848\n",
      "LightGBM Accuracy: 0.783125\n",
      "CatBoost Accuracy: 0.789375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 15\n",
      "XGBoost Accuracy: 0.778125\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 98\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -0.676720\n",
      "[LightGBM] [Info] Start training from score -0.709848\n",
      "LightGBM Accuracy: 0.78125\n",
      "CatBoost Accuracy: 0.7775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 16\n",
      "XGBoost Accuracy: 0.77875\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000935 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 99\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -0.677028\n",
      "[LightGBM] [Info] Start training from score -0.709531\n",
      "LightGBM Accuracy: 0.78\n",
      "CatBoost Accuracy: 0.780625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 17\n",
      "XGBoost Accuracy: 0.798125\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000935 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 98\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -0.676720\n",
      "[LightGBM] [Info] Start training from score -0.709848\n",
      "LightGBM Accuracy: 0.80625\n",
      "CatBoost Accuracy: 0.80375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 18\n",
      "XGBoost Accuracy: 0.778125\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000940 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 99\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -0.676720\n",
      "[LightGBM] [Info] Start training from score -0.709848\n",
      "LightGBM Accuracy: 0.7775\n",
      "CatBoost Accuracy: 0.775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 19\n",
      "XGBoost Accuracy: 0.791875\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001151 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 98\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -0.676720\n",
      "[LightGBM] [Info] Start training from score -0.709848\n",
      "LightGBM Accuracy: 0.783125\n",
      "CatBoost Accuracy: 0.789375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 20\n",
      "XGBoost Accuracy: 0.778125\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 98\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -0.676720\n",
      "[LightGBM] [Info] Start training from score -0.709848\n",
      "LightGBM Accuracy: 0.78125\n",
      "CatBoost Accuracy: 0.7775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 21\n",
      "XGBoost Accuracy: 0.77875\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000935 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 99\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -0.677028\n",
      "[LightGBM] [Info] Start training from score -0.709531\n",
      "LightGBM Accuracy: 0.78\n",
      "CatBoost Accuracy: 0.780625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 22\n",
      "XGBoost Accuracy: 0.798125\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 98\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -0.676720\n",
      "[LightGBM] [Info] Start training from score -0.709848\n",
      "LightGBM Accuracy: 0.80625\n",
      "CatBoost Accuracy: 0.80375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 23\n",
      "XGBoost Accuracy: 0.778125\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000943 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 99\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -0.676720\n",
      "[LightGBM] [Info] Start training from score -0.709848\n",
      "LightGBM Accuracy: 0.7775\n",
      "CatBoost Accuracy: 0.775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 24\n",
      "XGBoost Accuracy: 0.791875\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001713 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 98\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -0.676720\n",
      "[LightGBM] [Info] Start training from score -0.709848\n",
      "LightGBM Accuracy: 0.783125\n",
      "CatBoost Accuracy: 0.789375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:260: UserWarning: 'evals_result' argument is deprecated and will be removed in a future release of LightGBM. Pass 'record_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'evals_result' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 25\n",
      "XGBoost Accuracy: 0.778125\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003997 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 98\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -0.676720\n",
      "[LightGBM] [Info] Start training from score -0.709848\n",
      "LightGBM Accuracy: 0.78125\n",
      "CatBoost Accuracy: 0.7775\n"
     ]
    }
   ],
   "source": [
    "# 各5つのモデルを保存するリストの初期化\n",
    "xgb_models = []\n",
    "lgbm_models = []\n",
    "catb_models = []\n",
    "# 各5つのモデルの正答率を保存するリストの初期化\n",
    "xgb_accuracies = []\n",
    "lgbm_accuracies = []\n",
    "catb_accuracies = []\n",
    "# 学習のカウンター\n",
    "loop_counts = 1\n",
    "\n",
    "# 各クラスの確率（3モデル*5seed*３クラス）\n",
    "first_probs = pd.DataFrame(np.zeros((len(df_X), 3*5*2)))\n",
    "\n",
    "# count = 0\n",
    "for seed_no in range(5): \n",
    "#     print('count: {}'.format(str(count)))\n",
    "#     if count >= 2:\n",
    "#         print('----------------end----------------')\n",
    "#         break\n",
    "        \n",
    "#     count += 1\n",
    "    \n",
    "    # 学習データの数だけの数列（0行から最終行まで連番）\n",
    "    row_no_list = list(range(len(df_X)))\n",
    "\n",
    "    # KFoldクラスをインスタンス化（これを使って5分割する）\n",
    "    K_fold = StratifiedKFold(n_splits=5, shuffle=True,  random_state=42)\n",
    "\n",
    "    \n",
    "    # KFoldクラスで分割した回数だけ実行（ここでは5回）\n",
    "    for train_cv_no, eval_cv_no in K_fold.split(row_no_list, y):        \n",
    "        # ilocで取り出す行を指定\n",
    "        X_train_cv = df_X.iloc[train_cv_no, :]\n",
    "        y_train_cv = pd.Series(y).iloc[train_cv_no]\n",
    "        X_eval_cv = df_X.iloc[eval_cv_no, :]\n",
    "        y_eval_cv = pd.Series(y).iloc[eval_cv_no]\n",
    "        \n",
    "        # XGBoostの訓練を実行\n",
    "        bst, bst_accuracy, xgb_prob = xgb_train_cv(X_train_cv, y_train_cv,\n",
    "                                                   X_eval_cv, y_eval_cv, \n",
    "                                                   loop_counts)\n",
    "        # LIghtGBMの訓練を実行\n",
    "        model, model_accuracy, lgbm_prob = lgbm_train_cv(X_train_cv, y_train_cv, \n",
    "                                                         X_eval_cv, y_eval_cv)\n",
    "        # CatBoostの訓練を実行\n",
    "        catb, catb_accuracy, catb_prob = catboost_train_cv(X_train_cv, y_train_cv,\n",
    "                                                           X_eval_cv, y_eval_cv)\n",
    "        # 実行回数のカウント\n",
    "        loop_counts += 1\n",
    "        \n",
    "        # 学習が終わったモデルをリストに入れておく\n",
    "        xgb_models.append(bst) \n",
    "        lgbm_models.append(model) \n",
    "        catb_models.append(catb) \n",
    "        \n",
    "        # 学習が終わったモデルの正答率をリストに入れておく\n",
    "        xgb_accuracies.append(bst_accuracy) \n",
    "        lgbm_accuracies.append(model_accuracy) \n",
    "        catb_accuracies.append(catb_accuracy) \n",
    "        \n",
    "        # 検証データの各クラスの確率\n",
    "        for i in range(2):\n",
    "            first_probs.iloc[eval_cv_no, (seed_no * 2) + i] = xgb_prob[:, i]\n",
    "            first_probs.iloc[eval_cv_no, (seed_no * 2) + 10 + i] = lgbm_prob[:, i]\n",
    "            first_probs.iloc[eval_cv_no, (seed_no * 2) + 20 + i] = catb_prob[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b19644d-f8c8-4e17-8c95-ac3748726c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.580655</td>\n",
       "      <td>0.419345</td>\n",
       "      <td>0.580655</td>\n",
       "      <td>0.419345</td>\n",
       "      <td>0.580655</td>\n",
       "      <td>0.419345</td>\n",
       "      <td>0.580655</td>\n",
       "      <td>0.419345</td>\n",
       "      <td>0.580655</td>\n",
       "      <td>0.419345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.565190</td>\n",
       "      <td>0.434810</td>\n",
       "      <td>0.565190</td>\n",
       "      <td>0.434810</td>\n",
       "      <td>0.565190</td>\n",
       "      <td>0.434810</td>\n",
       "      <td>0.565190</td>\n",
       "      <td>0.434810</td>\n",
       "      <td>0.565190</td>\n",
       "      <td>0.434810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.595935</td>\n",
       "      <td>0.404065</td>\n",
       "      <td>0.595935</td>\n",
       "      <td>0.404065</td>\n",
       "      <td>0.595935</td>\n",
       "      <td>0.404065</td>\n",
       "      <td>0.595935</td>\n",
       "      <td>0.404065</td>\n",
       "      <td>0.595935</td>\n",
       "      <td>0.404065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.436360</td>\n",
       "      <td>0.563640</td>\n",
       "      <td>0.436360</td>\n",
       "      <td>0.563640</td>\n",
       "      <td>0.436360</td>\n",
       "      <td>0.563640</td>\n",
       "      <td>0.436360</td>\n",
       "      <td>0.563640</td>\n",
       "      <td>0.436360</td>\n",
       "      <td>0.563640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.934326</td>\n",
       "      <td>0.065674</td>\n",
       "      <td>0.934326</td>\n",
       "      <td>0.065674</td>\n",
       "      <td>0.934326</td>\n",
       "      <td>0.065674</td>\n",
       "      <td>0.934326</td>\n",
       "      <td>0.065674</td>\n",
       "      <td>0.934326</td>\n",
       "      <td>0.065674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.937096</td>\n",
       "      <td>0.062904</td>\n",
       "      <td>0.937096</td>\n",
       "      <td>0.062904</td>\n",
       "      <td>0.937096</td>\n",
       "      <td>0.062904</td>\n",
       "      <td>0.937096</td>\n",
       "      <td>0.062904</td>\n",
       "      <td>0.937096</td>\n",
       "      <td>0.062904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.370788</td>\n",
       "      <td>0.629212</td>\n",
       "      <td>0.370788</td>\n",
       "      <td>0.629212</td>\n",
       "      <td>0.370788</td>\n",
       "      <td>0.629212</td>\n",
       "      <td>0.370788</td>\n",
       "      <td>0.629212</td>\n",
       "      <td>0.370788</td>\n",
       "      <td>0.629212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412068</td>\n",
       "      <td>0.587932</td>\n",
       "      <td>0.412068</td>\n",
       "      <td>0.587932</td>\n",
       "      <td>0.412068</td>\n",
       "      <td>0.587932</td>\n",
       "      <td>0.412068</td>\n",
       "      <td>0.587932</td>\n",
       "      <td>0.412068</td>\n",
       "      <td>0.587932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.949020</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.949020</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.949020</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.949020</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.949020</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.937537</td>\n",
       "      <td>0.062463</td>\n",
       "      <td>0.937537</td>\n",
       "      <td>0.062463</td>\n",
       "      <td>0.937537</td>\n",
       "      <td>0.062463</td>\n",
       "      <td>0.937537</td>\n",
       "      <td>0.062463</td>\n",
       "      <td>0.937537</td>\n",
       "      <td>0.062463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>0.063863</td>\n",
       "      <td>0.936137</td>\n",
       "      <td>0.063863</td>\n",
       "      <td>0.936137</td>\n",
       "      <td>0.063863</td>\n",
       "      <td>0.936137</td>\n",
       "      <td>0.063863</td>\n",
       "      <td>0.936137</td>\n",
       "      <td>0.063863</td>\n",
       "      <td>0.936137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067467</td>\n",
       "      <td>0.932533</td>\n",
       "      <td>0.067467</td>\n",
       "      <td>0.932533</td>\n",
       "      <td>0.067467</td>\n",
       "      <td>0.932533</td>\n",
       "      <td>0.067467</td>\n",
       "      <td>0.932533</td>\n",
       "      <td>0.067467</td>\n",
       "      <td>0.932533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>0.691422</td>\n",
       "      <td>0.308578</td>\n",
       "      <td>0.691422</td>\n",
       "      <td>0.308578</td>\n",
       "      <td>0.691422</td>\n",
       "      <td>0.308578</td>\n",
       "      <td>0.691422</td>\n",
       "      <td>0.308578</td>\n",
       "      <td>0.691422</td>\n",
       "      <td>0.308578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.611099</td>\n",
       "      <td>0.388901</td>\n",
       "      <td>0.611099</td>\n",
       "      <td>0.388901</td>\n",
       "      <td>0.611099</td>\n",
       "      <td>0.388901</td>\n",
       "      <td>0.611099</td>\n",
       "      <td>0.388901</td>\n",
       "      <td>0.611099</td>\n",
       "      <td>0.388901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>0.076721</td>\n",
       "      <td>0.923279</td>\n",
       "      <td>0.076721</td>\n",
       "      <td>0.923279</td>\n",
       "      <td>0.076721</td>\n",
       "      <td>0.923279</td>\n",
       "      <td>0.076721</td>\n",
       "      <td>0.923279</td>\n",
       "      <td>0.076721</td>\n",
       "      <td>0.923279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063214</td>\n",
       "      <td>0.936786</td>\n",
       "      <td>0.063214</td>\n",
       "      <td>0.936786</td>\n",
       "      <td>0.063214</td>\n",
       "      <td>0.936786</td>\n",
       "      <td>0.063214</td>\n",
       "      <td>0.936786</td>\n",
       "      <td>0.063214</td>\n",
       "      <td>0.936786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>0.120339</td>\n",
       "      <td>0.879661</td>\n",
       "      <td>0.120339</td>\n",
       "      <td>0.879661</td>\n",
       "      <td>0.120339</td>\n",
       "      <td>0.879661</td>\n",
       "      <td>0.120339</td>\n",
       "      <td>0.879661</td>\n",
       "      <td>0.120339</td>\n",
       "      <td>0.879661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149198</td>\n",
       "      <td>0.850802</td>\n",
       "      <td>0.149198</td>\n",
       "      <td>0.850802</td>\n",
       "      <td>0.149198</td>\n",
       "      <td>0.850802</td>\n",
       "      <td>0.149198</td>\n",
       "      <td>0.850802</td>\n",
       "      <td>0.149198</td>\n",
       "      <td>0.850802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>0.918663</td>\n",
       "      <td>0.081337</td>\n",
       "      <td>0.918663</td>\n",
       "      <td>0.081337</td>\n",
       "      <td>0.918663</td>\n",
       "      <td>0.081337</td>\n",
       "      <td>0.918663</td>\n",
       "      <td>0.081337</td>\n",
       "      <td>0.918663</td>\n",
       "      <td>0.081337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.846838</td>\n",
       "      <td>0.153162</td>\n",
       "      <td>0.846838</td>\n",
       "      <td>0.153162</td>\n",
       "      <td>0.846838</td>\n",
       "      <td>0.153162</td>\n",
       "      <td>0.846838</td>\n",
       "      <td>0.153162</td>\n",
       "      <td>0.846838</td>\n",
       "      <td>0.153162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     0.580655  0.419345  0.580655  0.419345  0.580655  0.419345  0.580655   \n",
       "1     0.595935  0.404065  0.595935  0.404065  0.595935  0.404065  0.595935   \n",
       "2     0.934326  0.065674  0.934326  0.065674  0.934326  0.065674  0.934326   \n",
       "3     0.370788  0.629212  0.370788  0.629212  0.370788  0.629212  0.370788   \n",
       "4     0.949020  0.050980  0.949020  0.050980  0.949020  0.050980  0.949020   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "7995  0.063863  0.936137  0.063863  0.936137  0.063863  0.936137  0.063863   \n",
       "7996  0.691422  0.308578  0.691422  0.308578  0.691422  0.308578  0.691422   \n",
       "7997  0.076721  0.923279  0.076721  0.923279  0.076721  0.923279  0.076721   \n",
       "7998  0.120339  0.879661  0.120339  0.879661  0.120339  0.879661  0.120339   \n",
       "7999  0.918663  0.081337  0.918663  0.081337  0.918663  0.081337  0.918663   \n",
       "\n",
       "            7         8         9   ...        20        21        22  \\\n",
       "0     0.419345  0.580655  0.419345  ...  0.565190  0.434810  0.565190   \n",
       "1     0.404065  0.595935  0.404065  ...  0.436360  0.563640  0.436360   \n",
       "2     0.065674  0.934326  0.065674  ...  0.937096  0.062904  0.937096   \n",
       "3     0.629212  0.370788  0.629212  ...  0.412068  0.587932  0.412068   \n",
       "4     0.050980  0.949020  0.050980  ...  0.937537  0.062463  0.937537   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "7995  0.936137  0.063863  0.936137  ...  0.067467  0.932533  0.067467   \n",
       "7996  0.308578  0.691422  0.308578  ...  0.611099  0.388901  0.611099   \n",
       "7997  0.923279  0.076721  0.923279  ...  0.063214  0.936786  0.063214   \n",
       "7998  0.879661  0.120339  0.879661  ...  0.149198  0.850802  0.149198   \n",
       "7999  0.081337  0.918663  0.081337  ...  0.846838  0.153162  0.846838   \n",
       "\n",
       "            23        24        25        26        27        28        29  \n",
       "0     0.434810  0.565190  0.434810  0.565190  0.434810  0.565190  0.434810  \n",
       "1     0.563640  0.436360  0.563640  0.436360  0.563640  0.436360  0.563640  \n",
       "2     0.062904  0.937096  0.062904  0.937096  0.062904  0.937096  0.062904  \n",
       "3     0.587932  0.412068  0.587932  0.412068  0.587932  0.412068  0.587932  \n",
       "4     0.062463  0.937537  0.062463  0.937537  0.062463  0.937537  0.062463  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "7995  0.932533  0.067467  0.932533  0.067467  0.932533  0.067467  0.932533  \n",
       "7996  0.388901  0.611099  0.388901  0.611099  0.388901  0.611099  0.388901  \n",
       "7997  0.936786  0.063214  0.936786  0.063214  0.936786  0.063214  0.936786  \n",
       "7998  0.850802  0.149198  0.850802  0.149198  0.850802  0.149198  0.850802  \n",
       "7999  0.153162  0.846838  0.153162  0.846838  0.153162  0.846838  0.153162  \n",
       "\n",
       "[8000 rows x 30 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c964cde5-63f5-42c5-b98e-daeea5eb7b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 0\n",
      "Accuracy: 0.78875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 1\n",
      "Accuracy: 0.79125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 2\n",
      "Accuracy: 0.790625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 3\n",
      "Accuracy: 0.789375\n",
      "Trial: 4\n",
      "Accuracy: 0.7925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "loop_counts = 1\n",
    "\n",
    "# 学習データとテストデータに分ける\n",
    "X_train, X_test, y_train, y_test = train_test_split(first_probs, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=0,\n",
    "                                                    stratify=y)\n",
    "\n",
    "# 予測結果の格納用のnumpy行列を作成\n",
    "test_preds = np.zeros((len(y_test), 5))\n",
    "\n",
    "# 学習データの数だけの数列（0行から最終行まで連番）\n",
    "row_no_list = list(range(len(y_train)))\n",
    "\n",
    "# KFoldクラスをインスタンス化（これを使って5分割する）\n",
    "K_fold = StratifiedKFold(n_splits=5, shuffle=True,  random_state=0)\n",
    "\n",
    "# KFoldクラスで分割した回数だけ実行（ここでは5回）\n",
    "for train_cv_no, eval_cv_no in K_fold.split(row_no_list, y_train):\n",
    "    # ilocで取り出す行を指定\n",
    "    X_train_cv = X_train.iloc[train_cv_no, :]\n",
    "    y_train_cv = pd.Series(y_train).iloc[train_cv_no]\n",
    "    X_eval_cv = X_train.iloc[eval_cv_no, :]\n",
    "    y_eval_cv = pd.Series(y_train).iloc[eval_cv_no]\n",
    "\n",
    "    # データを格納する\n",
    "    # 学習用\n",
    "    xgb_train = xgb.DMatrix(X_train_cv, label=y_train_cv)\n",
    "    # 検証用\n",
    "    xgb_eval = xgb.DMatrix(X_eval_cv, label=y_eval_cv)\n",
    "    # テスト用\n",
    "    xgb_test = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "    xgb_params = {\n",
    "        'objective': 'multi:softprob',  # 多値分類問題\n",
    "        'num_class': 2,                 # 目的変数のクラス数\n",
    "        'learning_rate': 0.1,           # 学習率\n",
    "        'eval_metric': 'mlogloss'       # 学習用の指標 (Multiclass logloss)\n",
    "    }\n",
    "\n",
    "    # 学習\n",
    "    evals = [(xgb_train, 'train'), (xgb_eval, 'eval')] # 学習に用いる検証用データ\n",
    "    evaluation_results = {}                            # 学習の経過を保存する箱\n",
    "    bst = xgb.train(xgb_params,                        # 上記で設定したパラメータ\n",
    "                    xgb_train,                         # 使用するデータセット\n",
    "                    num_boost_round=200,               # 学習の回数\n",
    "                    early_stopping_rounds=10,          # アーリーストッピング\n",
    "                    evals=evals,                       # 学習経過で表示する名称\n",
    "                    evals_result=evaluation_results,   # 上記で設定した検証用データ\n",
    "                    verbose_eval=0                     # 学習の経過の表示(非表示)\n",
    "                    )\n",
    "\n",
    "\n",
    "    y_pred = bst.predict(xgb_test, ntree_limit=bst.best_ntree_limit)\n",
    "    y_pred_max = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    # testの予測を保存\n",
    "    test_preds[:, loop_counts] = y_pred_max\n",
    " \n",
    "    print('Trial: ' + str(loop_counts))\n",
    "    loop_counts += 1\n",
    "    acc = accuracy_score(y_test, y_pred_max)\n",
    "    print('Accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91de836e-120d-4533-81b3-b6c3690cbc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.790625\n",
      "y_pred_max    0    1\n",
      "va_y                \n",
      "0           641  172\n",
      "1           163  624\n"
     ]
    }
   ],
   "source": [
    "# 予測したクラスのデータをpandas.DataFrameに入れる\n",
    "df_test_preds = pd.DataFrame(test_preds)\n",
    "\n",
    "# ５つの予測の格納用のnumpy行列を作成\n",
    "test_preds_max = np.zeros((len(y_test), 3))\n",
    "\n",
    "# 各列（0,1,2）に、そのクラスを予測したモデルの数を入れる\n",
    "test_preds_max[:, 0] = (df_test_preds == 0).sum(axis=1)\n",
    "test_preds_max[:, 1] = (df_test_preds == 1).sum(axis=1)\n",
    "test_preds_max[:, 2] = (df_test_preds == 2).sum(axis=1)\n",
    "\n",
    "# 各行で、そのクラスを予測したモデルの数が最も多いクラスを得る\n",
    "pred_max = np.argmax(test_preds_max, axis=1)\n",
    "\n",
    "# Accuracy を計算する\n",
    "accuracy = sum(y_test == pred_max) / len(y_test)\n",
    "print('accuracy:', accuracy)\n",
    "\n",
    "df_accuracy = pd.DataFrame({'va_y': y_test,\n",
    "                            'y_pred_max': pred_max})\n",
    "print(pd.crosstab(df_accuracy['va_y'], df_accuracy['y_pred_max']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce07032b-a16f-4794-89be-26bd8f259200",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
